train: True
dataset_path:  ${hydra:runtime.cwd}/dataset/tokenizable_dataset/train/few_shot_markdown_fact_first_structured.json
dataset_label: few_shot_markdown_fact_first_structured
# wandb:
#   model_id: ${model.model_label}
#   project_name: thesis_sft
#   run_name: qlora_finetuning

lora_config:
  r: 8
  lora_alpha: 16
  bias: "none"
  lora_dropout: 0.1
  task_type: "CAUSAL_LM"
  target_modules: [
    "q_proj",
    "up_proj",
    "o_proj",
    "k_proj",
    "down_proj",
    "gate_proj",
    "v_proj"]

training_args:
  output_dir: /work/ws/fr_rf129-thesis_workspace/train_results
  num_train_epochs: 5
  per_device_train_batch_size: 2
  gradient_checkpointing: True
  gradient_accumulation_steps: 1
  optim: "paged_adamw_32bit"
  save_steps: 25
  logging_steps: 10
  learning_rate: 2e-4
  weight_decay: 0.001
  fp16: False
  bf16: False
  max_grad_norm: 0.3
  max_steps: -1
  group_by_length: True
  lr_scheduler_type: "constant"
  report_to: "wandb"

new_model_name: ${model.model_label}_${train.dataset_label}
model_save_directory: /work/ws/fr_rf129-thesis_workspace/saved_models/${train.new_model_name}