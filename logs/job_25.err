Unused kwargs: ['use_nested_quant']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.52s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 808.89 examples/s]
wandb: Currently logged in as: rean-fernandes. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.3
wandb: Run data is saved locally in /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/wandb/run-20250306_190356-ifoyodl3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine_tune_json_fact_first_few_shot_structured_seed_314_llama2
wandb: ⭐️ View project at https://wandb.ai/rean-fernandes/Final_runs_paper
wandb: 🚀 View run at https://wandb.ai/rean-fernandes/Final_runs_paper/runs/ifoyodl3
  0%|          | 0/150 [00:00<?, ?it/s]  1%|          | 1/150 [00:24<1:00:06, 24.20s/it]  1%|▏         | 2/150 [00:48<59:09, 23.99s/it]    2%|▏         | 3/150 [01:11<58:42, 23.96s/it]                                                 2%|▏         | 3/150 [01:11<58:42, 23.96s/it]  3%|▎         | 4/150 [01:35<58:20, 23.98s/it]  3%|▎         | 5/150 [01:59<57:54, 23.96s/it]  4%|▍         | 6/150 [02:23<57:29, 23.96s/it]                                                 4%|▍         | 6/150 [02:23<57:29, 23.96s/it]  5%|▍         | 7/150 [02:47<57:07, 23.97s/it]  5%|▌         | 8/150 [03:11<56:44, 23.98s/it]  6%|▌         | 9/150 [03:35<56:22, 23.99s/it]                                                 6%|▌         | 9/150 [03:35<56:22, 23.99s/it]  7%|▋         | 10/150 [03:59<56:01, 24.01s/it]  7%|▋         | 11/150 [04:24<55:41, 24.04s/it]  8%|▊         | 12/150 [04:48<55:19, 24.06s/it]                                                  8%|▊         | 12/150 [04:48<55:19, 24.06s/it]  9%|▊         | 13/150 [05:12<54:58, 24.08s/it]  9%|▉         | 14/150 [05:36<54:38, 24.10s/it] 10%|█         | 15/150 [06:00<54:15, 24.12s/it]                                                 10%|█         | 15/150 [06:00<54:15, 24.12s/it] 11%|█         | 16/150 [06:24<53:53, 24.13s/it] 11%|█▏        | 17/150 [06:48<53:30, 24.14s/it] 12%|█▏        | 18/150 [07:13<53:07, 24.15s/it]                                                 12%|█▏        | 18/150 [07:13<53:07, 24.15s/it] 13%|█▎        | 19/150 [07:37<52:44, 24.15s/it] 13%|█▎        | 20/150 [08:01<52:19, 24.15s/it] 14%|█▍        | 21/150 [08:25<51:57, 24.17s/it]                                                 14%|█▍        | 21/150 [08:25<51:57, 24.17s/it] 15%|█▍        | 22/150 [08:49<51:33, 24.17s/it] 15%|█▌        | 23/150 [09:13<51:10, 24.17s/it] 16%|█▌        | 24/150 [09:38<50:46, 24.18s/it]                                                 16%|█▌        | 24/150 [09:38<50:46, 24.18s/it] 17%|█▋        | 25/150 [10:02<50:21, 24.17s/it] 17%|█▋        | 26/150 [10:26<49:57, 24.17s/it] 18%|█▊        | 27/150 [10:50<49:33, 24.17s/it]                                                 18%|█▊        | 27/150 [10:50<49:33, 24.17s/it] 19%|█▊        | 28/150 [11:14<49:09, 24.17s/it] 19%|█▉        | 29/150 [11:38<48:44, 24.17s/it] 20%|██        | 30/150 [12:03<48:21, 24.18s/it]                                                 20%|██        | 30/150 [12:03<48:21, 24.18s/it] 21%|██        | 31/150 [12:27<47:57, 24.18s/it] 21%|██▏       | 32/150 [12:51<47:34, 24.19s/it] 22%|██▏       | 33/150 [13:15<47:10, 24.19s/it]                                                 22%|██▏       | 33/150 [13:15<47:10, 24.19s/it] 23%|██▎       | 34/150 [13:39<46:46, 24.19s/it] 23%|██▎       | 35/150 [14:04<46:21, 24.19s/it] 24%|██▍       | 36/150 [14:28<45:57, 24.19s/it]                                                 24%|██▍       | 36/150 [14:28<45:57, 24.19s/it] 25%|██▍       | 37/150 [14:52<45:34, 24.20s/it] 25%|██▌       | 38/150 [15:16<45:10, 24.20s/it] 26%|██▌       | 39/150 [15:40<44:46, 24.20s/it]                                                 26%|██▌       | 39/150 [15:40<44:46, 24.20s/it] 27%|██▋       | 40/150 [16:05<44:20, 24.18s/it] 27%|██▋       | 41/150 [16:29<43:56, 24.19s/it] 28%|██▊       | 42/150 [16:53<43:32, 24.19s/it]                                                 28%|██▊       | 42/150 [16:53<43:32, 24.19s/it] 29%|██▊       | 43/150 [17:17<43:07, 24.18s/it] 29%|██▉       | 44/150 [17:41<42:43, 24.19s/it] 30%|███       | 45/150 [18:06<42:20, 24.20s/it]                                                 30%|███       | 45/150 [18:06<42:20, 24.20s/it] 31%|███       | 46/150 [18:30<41:57, 24.21s/it] 31%|███▏      | 47/150 [18:54<41:32, 24.20s/it] 32%|███▏      | 48/150 [19:18<41:08, 24.20s/it]                                                 32%|███▏      | 48/150 [19:18<41:08, 24.20s/it] 33%|███▎      | 49/150 [19:42<40:43, 24.20s/it] 33%|███▎      | 50/150 [20:07<40:19, 24.19s/it] 34%|███▍      | 51/150 [20:31<39:55, 24.19s/it]                                                 34%|███▍      | 51/150 [20:31<39:55, 24.19s/it] 35%|███▍      | 52/150 [20:55<39:31, 24.19s/it] 35%|███▌      | 53/150 [21:19<39:07, 24.20s/it] 36%|███▌      | 54/150 [21:43<38:42, 24.20s/it]                                                 36%|███▌      | 54/150 [21:43<38:42, 24.20s/it] 37%|███▋      | 55/150 [22:08<38:18, 24.20s/it] 37%|███▋      | 56/150 [22:32<37:54, 24.19s/it] 38%|███▊      | 57/150 [22:56<37:29, 24.18s/it]                                                 38%|███▊      | 57/150 [22:56<37:29, 24.18s/it] 39%|███▊      | 58/150 [23:20<37:05, 24.19s/it] 39%|███▉      | 59/150 [23:44<36:41, 24.19s/it] 40%|████      | 60/150 [24:08<36:17, 24.19s/it]                                                 40%|████      | 60/150 [24:08<36:17, 24.19s/it] 41%|████      | 61/150 [24:33<35:52, 24.19s/it] 41%|████▏     | 62/150 [24:57<35:28, 24.19s/it] 42%|████▏     | 63/150 [25:21<35:04, 24.19s/it]                                                 42%|████▏     | 63/150 [25:21<35:04, 24.19s/it] 43%|████▎     | 64/150 [25:45<34:40, 24.20s/it] 43%|████▎     | 65/150 [26:09<34:16, 24.20s/it] 44%|████▍     | 66/150 [26:34<33:52, 24.19s/it]                                                 44%|████▍     | 66/150 [26:34<33:52, 24.19s/it] 45%|████▍     | 67/150 [26:58<33:28, 24.20s/it] 45%|████▌     | 68/150 [27:22<33:04, 24.20s/it] 46%|████▌     | 69/150 [27:46<32:39, 24.20s/it]                                                 46%|████▌     | 69/150 [27:46<32:39, 24.20s/it] 47%|████▋     | 70/150 [28:10<32:15, 24.19s/it] 47%|████▋     | 71/150 [28:35<31:51, 24.20s/it] 48%|████▊     | 72/150 [28:59<31:27, 24.20s/it]                                                 48%|████▊     | 72/150 [28:59<31:27, 24.20s/it] 49%|████▊     | 73/150 [29:23<31:03, 24.20s/it] 49%|████▉     | 74/150 [29:47<30:39, 24.20s/it] 50%|█████     | 75/150 [30:11<30:15, 24.20s/it]                                                 50%|█████     | 75/150 [30:11<30:15, 24.20s/it] 51%|█████     | 76/150 [30:36<29:50, 24.20s/it] 51%|█████▏    | 77/150 [31:00<29:26, 24.20s/it] 52%|█████▏    | 78/150 [31:24<29:02, 24.20s/it]                                                 52%|█████▏    | 78/150 [31:24<29:02, 24.20s/it] 53%|█████▎    | 79/150 [31:48<28:38, 24.21s/it] 53%|█████▎    | 80/150 [32:12<28:14, 24.20s/it] 54%|█████▍    | 81/150 [32:37<27:49, 24.20s/it]                                                 54%|█████▍    | 81/150 [32:37<27:49, 24.20s/it] 55%|█████▍    | 82/150 [33:01<27:25, 24.19s/it] 55%|█████▌    | 83/150 [33:25<27:01, 24.20s/it] 56%|█████▌    | 84/150 [33:49<26:37, 24.20s/it]                                                 56%|█████▌    | 84/150 [33:49<26:37, 24.20s/it] 57%|█████▋    | 85/150 [34:13<26:13, 24.20s/it] 57%|█████▋    | 86/150 [34:38<25:49, 24.20s/it] 58%|█████▊    | 87/150 [35:02<25:24, 24.20s/it]                                                 58%|█████▊    | 87/150 [35:02<25:24, 24.20s/it] 59%|█████▊    | 88/150 [35:26<25:00, 24.20s/it] 59%|█████▉    | 89/150 [35:50<24:36, 24.20s/it] 60%|██████    | 90/150 [36:14<24:11, 24.20s/it]                                                 60%|██████    | 90/150 [36:14<24:11, 24.20s/it] 61%|██████    | 91/150 [36:39<23:47, 24.20s/it] 61%|██████▏   | 92/150 [37:03<23:23, 24.19s/it] 62%|██████▏   | 93/150 [37:27<22:58, 24.19s/it]                                                 62%|██████▏   | 93/150 [37:27<22:58, 24.19s/it] 63%|██████▎   | 94/150 [37:51<22:34, 24.19s/it] 63%|██████▎   | 95/150 [38:15<22:10, 24.19s/it] 64%|██████▍   | 96/150 [38:40<21:46, 24.19s/it]                                                 64%|██████▍   | 96/150 [38:40<21:46, 24.19s/it] 65%|██████▍   | 97/150 [39:04<21:22, 24.19s/it] 65%|██████▌   | 98/150 [39:28<20:57, 24.19s/it] 66%|██████▌   | 99/150 [39:52<20:33, 24.19s/it]                                                 66%|██████▌   | 99/150 [39:52<20:33, 24.19s/it] 67%|██████▋   | 100/150 [40:16<20:09, 24.19s/it] 67%|██████▋   | 101/150 [40:40<19:44, 24.18s/it] 68%|██████▊   | 102/150 [41:05<19:21, 24.19s/it]                                                  68%|██████▊   | 102/150 [41:05<19:21, 24.19s/it] 69%|██████▊   | 103/150 [41:29<18:57, 24.20s/it] 69%|██████▉   | 104/150 [41:53<18:33, 24.20s/it] 70%|███████   | 105/150 [42:17<18:08, 24.20s/it]                                                  70%|███████   | 105/150 [42:17<18:08, 24.20s/it] 71%|███████   | 106/150 [42:42<17:44, 24.19s/it] 71%|███████▏  | 107/150 [43:06<17:20, 24.19s/it] 72%|███████▏  | 108/150 [43:30<16:55, 24.18s/it]                                                  72%|███████▏  | 108/150 [43:30<16:55, 24.18s/it] 73%|███████▎  | 109/150 [43:54<16:31, 24.19s/it] 73%|███████▎  | 110/150 [44:18<16:07, 24.18s/it] 74%|███████▍  | 111/150 [44:42<15:43, 24.19s/it]                                                  74%|███████▍  | 111/150 [44:42<15:43, 24.19s/it] 75%|███████▍  | 112/150 [45:07<15:19, 24.20s/it] 75%|███████▌  | 113/150 [45:31<14:55, 24.20s/it] 76%|███████▌  | 114/150 [45:55<14:31, 24.20s/it]                                                  76%|███████▌  | 114/150 [45:55<14:31, 24.20s/it] 77%|███████▋  | 115/150 [46:19<14:06, 24.19s/it] 77%|███████▋  | 116/150 [46:43<13:42, 24.19s/it] 78%|███████▊  | 117/150 [47:08<13:18, 24.20s/it]                                                  78%|███████▊  | 117/150 [47:08<13:18, 24.20s/it] 79%|███████▊  | 118/150 [47:32<12:54, 24.20s/it] 79%|███████▉  | 119/150 [47:56<12:30, 24.20s/it] 80%|████████  | 120/150 [48:20<12:05, 24.19s/it]                                                  80%|████████  | 120/150 [48:20<12:05, 24.19s/it] 81%|████████  | 121/150 [48:44<11:41, 24.20s/it] 81%|████████▏ | 122/150 [49:09<11:17, 24.19s/it] 82%|████████▏ | 123/150 [49:33<10:53, 24.19s/it]                                                  82%|████████▏ | 123/150 [49:33<10:53, 24.19s/it] 83%|████████▎ | 124/150 [49:57<10:29, 24.19s/it] 83%|████████▎ | 125/150 [50:21<10:04, 24.20s/it] 84%|████████▍ | 126/150 [50:45<09:40, 24.20s/it]                                                  84%|████████▍ | 126/150 [50:45<09:40, 24.20s/it] 85%|████████▍ | 127/150 [51:10<09:16, 24.20s/it] 85%|████████▌ | 128/150 [51:34<08:52, 24.20s/it] 86%|████████▌ | 129/150 [51:58<08:27, 24.19s/it]                                                  86%|████████▌ | 129/150 [51:58<08:27, 24.19s/it] 87%|████████▋ | 130/150 [52:22<08:03, 24.19s/it] 87%|████████▋ | 131/150 [52:46<07:39, 24.18s/it] 88%|████████▊ | 132/150 [53:10<07:15, 24.17s/it]                                                  88%|████████▊ | 132/150 [53:10<07:15, 24.17s/it] 89%|████████▊ | 133/150 [53:35<06:50, 24.18s/it] 89%|████████▉ | 134/150 [53:59<06:26, 24.19s/it] 90%|█████████ | 135/150 [54:23<06:02, 24.19s/it]                                                  90%|█████████ | 135/150 [54:23<06:02, 24.19s/it] 91%|█████████ | 136/150 [54:47<05:38, 24.20s/it] 91%|█████████▏| 137/150 [55:11<05:14, 24.20s/it] 92%|█████████▏| 138/150 [55:36<04:50, 24.20s/it]                                                  92%|█████████▏| 138/150 [55:36<04:50, 24.20s/it] 93%|█████████▎| 139/150 [56:00<04:26, 24.20s/it] 93%|█████████▎| 140/150 [56:24<04:02, 24.20s/it] 94%|█████████▍| 141/150 [56:48<03:37, 24.20s/it]                                                  94%|█████████▍| 141/150 [56:48<03:37, 24.20s/it] 95%|█████████▍| 142/150 [57:12<03:13, 24.20s/it] 95%|█████████▌| 143/150 [57:37<02:49, 24.20s/it] 96%|█████████▌| 144/150 [58:01<02:25, 24.21s/it]                                                  96%|█████████▌| 144/150 [58:01<02:25, 24.21s/it] 97%|█████████▋| 145/150 [58:25<02:01, 24.21s/it] 97%|█████████▋| 146/150 [58:49<01:36, 24.20s/it] 98%|█████████▊| 147/150 [59:13<01:12, 24.20s/it]                                                  98%|█████████▊| 147/150 [59:13<01:12, 24.20s/it] 99%|█████████▊| 148/150 [59:38<00:48, 24.20s/it] 99%|█████████▉| 149/150 [1:00:02<00:24, 24.21s/it]100%|██████████| 150/150 [1:00:26<00:00, 24.20s/it]                                                   100%|██████████| 150/150 [1:00:26<00:00, 24.20s/it]                                                   100%|██████████| 150/150 [1:00:26<00:00, 24.20s/it]100%|██████████| 150/150 [1:00:26<00:00, 24.18s/it]
/pfs/data5/home/fr/fr_fr/fr_rf1031/llama-env/lib64/python3.11/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:         train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████
wandb:   train/global_step ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:     train/grad_norm ▃▄▄▅▆▆▇▄▂▁▂▁▁▁▁▁▁▁▁▁▂▂▂▂▃▄▄▅▇▇▅▅▇█▆▄▆▅▄▄
wandb: train/learning_rate ▂▄▅▇███▇▇▇▆▆▅▅▄▃▃▂▂▂▁▁███▇▇▇▆▆▅▄▄▃▃▂▂▂▁▁
wandb:          train/loss ███▇▆▄▃▃▃▃▃▃▃▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:               total_flos 4.36569190170624e+16
wandb:              train/epoch 15
wandb:        train/global_step 150
wandb:          train/grad_norm 0.16203
wandb:      train/learning_rate 0
wandb:               train/loss 0.0431
wandb:               train_loss 0.3673
wandb:            train_runtime 3627.7289
wandb: train_samples_per_second 0.289
wandb:   train_steps_per_second 0.041
wandb: 
wandb: 🚀 View run fine_tune_json_fact_first_few_shot_structured_seed_314_llama2 at: https://wandb.ai/rean-fernandes/Final_runs_paper/runs/ifoyodl3
wandb: ⭐️ View project at: https://wandb.ai/rean-fernandes/Final_runs_paper
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250306_190356-ifoyodl3/logs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.68s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
/pfs/data5/home/fr/fr_fr/fr_rf1031/llama-env/lib64/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/pfs/data5/home/fr/fr_fr/fr_rf1031/llama-env/lib64/python3.11/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:12<00:12, 12.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  6.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.66s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.77s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
