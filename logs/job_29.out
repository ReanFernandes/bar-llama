Starting job 29 at Thu Mar  6 20:24:53 CET 2025
Configuration: model=llama2 tokenizer=llama2 dataset=all_domains_10_samples prompt=json_fact_first_zero_shot_structured train=json_fact_first_zero_shot_structured ++train.training_args.per_device_train_batch_size=7 ++train.training_args.gradient_accumulation_steps=1
Starting update_status.py
Received arguments: ['/pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/scripts/update_status.py', '29', 'training']
Updating job 29 to status training with exit code None
Status update completed for job 29
[2025-03-06 20:25:12,578][root][INFO] - Global seed set to 314
[2025-03-06 20:25:12,580][root][WARNING] - Quantisation will be done on loaded model, THIS IS A QLORA FINE-TUNING RUN
[2025-03-06 20:25:12,580][root][WARNING] - Following flags are set for the run : 
 Use Quantisation before fine-tuning : True 
 Perform Validation on epoch end : False
[2025-03-06 20:25:12,580][root][INFO] - Running Fine-tuning on the all_domains_10_samples dataset
[2025-03-06 20:25:12,580][root][INFO] - Current training config is : 
 Prompt type : zero_shot 
 Response type : fact_first 
 Explanation type : structured 
 Response Format : json 
[2025-03-06 20:25:12,581][root][INFO] - Loading dataset from /home/fr/fr_fr/fr_rf1031/bar-llama/dataset/seed_dataset/distilled_dataset.json
[2025-03-06 20:25:12,669][root][INFO] - Dataset loaded successfully, indexing questions...
[2025-03-06 20:25:12,675][root][INFO] - Indexing complete, sampling of questions set to True
[2025-03-06 20:25:12,779][root][INFO] - Questions selected, dataset contains 70 questions with 10.0 questions per domain
[2025-03-06 20:25:12,783][root][INFO] - Prompt Handler initialized with configuration: {'prompt_type': 'zero_shot', 'example_path': '${hydra:runtime.cwd}/prompt/examples/structured_example.json', 'explanation_type': 'structured', 'response_type': 'fact_first', 'response_format': 'json', 'store_prompt': True, 'system_prompt': '${hydra:runtime.cwd}/prompt/system_prompt/system_${train.prompt.response_format}_${train.prompt.response_type}_${train.prompt.explanation_type}.txt', 'include_system_prompt': True}
[2025-03-06 20:25:13,253][root][INFO] - Tokenizer meta-llama/Llama-2-7b-hf loaded successfully
[2025-03-06 20:25:22,913][root][INFO] - Quantised model meta-llama/Llama-2-7b-hf loaded successfully
[2025-03-06 20:25:57,576][root][INFO] - Model prepared for kbit training
[2025-03-06 20:25:57,577][root][INFO] - Lora config loaded, following are the details : 
 LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=64, target_modules={'q_proj', 'k_proj', 'o_proj', 'down_proj', 'up_proj', 'v_proj', 'gate_proj'}, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))
[2025-03-06 20:25:59,444][root][INFO] - Lora adapter added to model
[2025-03-06 20:25:59,448][root][INFO] - Model adapter will be saved to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/sft_adapters/llama2/all_domains_10_samples/llama2_json_fact_first_zero_shot_structured
[2025-03-06 20:25:59,764][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'loss': 1.444, 'grad_norm': 0.12375859171152115, 'learning_rate': 2e-05, 'epoch': 0.3}
{'loss': 1.4366, 'grad_norm': 0.15023452043533325, 'learning_rate': 4e-05, 'epoch': 0.6}
{'loss': 1.4035, 'grad_norm': 0.1628960818052292, 'learning_rate': 6e-05, 'epoch': 0.9}
{'loss': 1.3361, 'grad_norm': 0.2099539190530777, 'learning_rate': 8e-05, 'epoch': 1.2}
{'loss': 1.2027, 'grad_norm': 0.1860591173171997, 'learning_rate': 0.0001, 'epoch': 1.5}
{'loss': 0.9744, 'grad_norm': 0.25910162925720215, 'learning_rate': 9.951340343707852e-05, 'epoch': 1.8}
{'loss': 0.9273, 'grad_norm': 0.20474621653556824, 'learning_rate': 9.806308479691595e-05, 'epoch': 2.1}
{'loss': 0.8089, 'grad_norm': 0.17786626517772675, 'learning_rate': 9.567727288213005e-05, 'epoch': 2.4}
{'loss': 0.8477, 'grad_norm': 0.1698705404996872, 'learning_rate': 9.24024048078213e-05, 'epoch': 2.7}
{'loss': 0.773, 'grad_norm': 0.1612882763147354, 'learning_rate': 8.83022221559489e-05, 'epoch': 3.0}
{'loss': 0.813, 'grad_norm': 0.1676439493894577, 'learning_rate': 8.345653031794292e-05, 'epoch': 3.3}
{'loss': 0.7373, 'grad_norm': 0.19497494399547577, 'learning_rate': 7.795964517353735e-05, 'epoch': 3.6}
{'loss': 0.748, 'grad_norm': 0.13208061456680298, 'learning_rate': 7.191855733945387e-05, 'epoch': 3.9}
{'loss': 0.7184, 'grad_norm': 0.1430060714483261, 'learning_rate': 6.545084971874738e-05, 'epoch': 4.2}
{'loss': 0.7324, 'grad_norm': 0.14633111655712128, 'learning_rate': 5.868240888334653e-05, 'epoch': 4.5}
{'loss': 0.6525, 'grad_norm': 0.15795598924160004, 'learning_rate': 5.174497483512506e-05, 'epoch': 4.8}
{'loss': 0.6935, 'grad_norm': 0.14818929135799408, 'learning_rate': 4.477357683661734e-05, 'epoch': 5.1}
{'loss': 0.6252, 'grad_norm': 0.17170450091362, 'learning_rate': 3.790390522001662e-05, 'epoch': 5.4}
{'loss': 0.6925, 'grad_norm': 0.19465535879135132, 'learning_rate': 3.12696703292044e-05, 'epoch': 5.7}
{'loss': 0.6288, 'grad_norm': 0.1814693808555603, 'learning_rate': 2.500000000000001e-05, 'epoch': 6.0}
{'loss': 0.6286, 'grad_norm': 0.1746053546667099, 'learning_rate': 1.9216926233717085e-05, 'epoch': 6.3}
{'loss': 0.5788, 'grad_norm': 0.19727617502212524, 'learning_rate': 1.4033009983067452e-05, 'epoch': 6.6}
{'loss': 0.6632, 'grad_norm': 0.19591470062732697, 'learning_rate': 9.549150281252633e-06, 'epoch': 6.9}
{'loss': 0.6089, 'grad_norm': 0.19843555986881256, 'learning_rate': 5.852620357053651e-06, 'epoch': 7.2}
{'loss': 0.6233, 'grad_norm': 0.21858252584934235, 'learning_rate': 3.0153689607045845e-06, 'epoch': 7.5}
{'loss': 0.5771, 'grad_norm': 0.21130022406578064, 'learning_rate': 1.0926199633097157e-06, 'epoch': 7.8}
{'loss': 0.598, 'grad_norm': 0.19929446280002594, 'learning_rate': 1.2179748700879012e-07, 'epoch': 8.1}
{'loss': 0.63, 'grad_norm': 0.2106892466545105, 'learning_rate': 9.987820251299122e-05, 'epoch': 8.4}
{'loss': 0.5832, 'grad_norm': 0.2867124080657959, 'learning_rate': 9.890738003669029e-05, 'epoch': 8.7}
{'loss': 0.5142, 'grad_norm': 0.3455881178379059, 'learning_rate': 9.698463103929542e-05, 'epoch': 9.0}
{'loss': 0.48, 'grad_norm': 0.3643498122692108, 'learning_rate': 9.414737964294636e-05, 'epoch': 9.3}
{'loss': 0.462, 'grad_norm': 0.3516753613948822, 'learning_rate': 9.045084971874738e-05, 'epoch': 9.6}
{'loss': 0.4737, 'grad_norm': 0.3867667317390442, 'learning_rate': 8.596699001693255e-05, 'epoch': 9.9}
{'loss': 0.3361, 'grad_norm': 0.43670356273651123, 'learning_rate': 8.07830737662829e-05, 'epoch': 10.2}
{'loss': 0.3337, 'grad_norm': 0.47915059328079224, 'learning_rate': 7.500000000000002e-05, 'epoch': 10.5}
{'loss': 0.2774, 'grad_norm': 0.41742581129074097, 'learning_rate': 6.873032967079561e-05, 'epoch': 10.8}
{'loss': 0.3032, 'grad_norm': 0.42655041813850403, 'learning_rate': 6.209609477998338e-05, 'epoch': 11.1}
{'loss': 0.151, 'grad_norm': 0.5420097708702087, 'learning_rate': 5.52264231633827e-05, 'epoch': 11.4}
{'loss': 0.2385, 'grad_norm': 0.46334847807884216, 'learning_rate': 4.825502516487497e-05, 'epoch': 11.7}
{'loss': 0.1825, 'grad_norm': 0.40437889099121094, 'learning_rate': 4.131759111665349e-05, 'epoch': 12.0}
{'loss': 0.1693, 'grad_norm': 0.47383835911750793, 'learning_rate': 3.454915028125262e-05, 'epoch': 12.3}
{'loss': 0.0977, 'grad_norm': 0.47031787037849426, 'learning_rate': 2.8081442660546142e-05, 'epoch': 12.6}
{'loss': 0.1151, 'grad_norm': 0.4524194002151489, 'learning_rate': 2.2040354826462668e-05, 'epoch': 12.9}
{'loss': 0.1026, 'grad_norm': 0.2647501528263092, 'learning_rate': 1.654346968205709e-05, 'epoch': 13.2}
{'loss': 0.0784, 'grad_norm': 0.30186256766319275, 'learning_rate': 1.1697777844051105e-05, 'epoch': 13.5}
{'loss': 0.0772, 'grad_norm': 0.2985609471797943, 'learning_rate': 7.597595192178702e-06, 'epoch': 13.8}
{'loss': 0.0853, 'grad_norm': 0.36689698696136475, 'learning_rate': 4.322727117869951e-06, 'epoch': 14.1}
{'loss': 0.0535, 'grad_norm': 0.2280072420835495, 'learning_rate': 1.93691520308405e-06, 'epoch': 14.4}
{'loss': 0.0672, 'grad_norm': 0.31374573707580566, 'learning_rate': 4.865965629214875e-07, 'epoch': 14.7}
{'loss': 0.06, 'grad_norm': 0.22620822489261627, 'learning_rate': 0.0, 'epoch': 15.0}
{'train_runtime': 3144.9801, 'train_samples_per_second': 0.334, 'train_steps_per_second': 0.048, 'train_loss': 0.5669097136457761, 'epoch': 15.0}
[2025-03-06 21:18:27,869][root][INFO] - Finetuning complete, model saved to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/sft_adapters/llama2/all_domains_10_samples/llama2_json_fact_first_zero_shot_structured
Starting update_status.py
Received arguments: ['/pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/scripts/update_status.py', '29', 'trained', '0']
Updating job 29 to status trained with exit code 0
Status update completed for job 29
Starting evaluations for job 29
Running evaluation with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_10_samples generation=greedy evaluation_dataset=test_set_1 eval=json_fact_first_zero_shot_structured ++eval.quantisation_status=full_model ++eval.training_status=trained
Starting update_eval_status.py
Received arguments: ['/pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/scripts/update_eval_status.py', '29', 'seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_10_samples generation=greedy evaluation_dataset=test_set_1 eval=json_fact_first_zero_shot_structured ++eval.quantisation_status=full_model ++eval.training_status=trained', 'running']
Updating eval for job 29 to status running with exit code None
Eval status update completed for job 29
[2025-03-06 21:18:37,821][root][INFO] - Setting global seed to 206
[2025-03-06 21:18:37,828][root][INFO] - Running evaluation of the trained model on the test_set_1
[2025-03-06 21:18:37,828][root][INFO] - Current evaluation config is : 
 Prompt type : zero_shot 
 Response type : fact_first 
 Explanation type : structured 
 Response Format : json 
[2025-03-06 21:18:37,830][root][INFO] - Loading dataset from /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/dataset/test_sets/bar_set_1.json
[2025-03-06 21:18:37,832][root][INFO] - Dataset loaded successfully, indexing questions...
[2025-03-06 21:18:37,837][root][INFO] - Indexing complete, sampling of questions set to False
[2025-03-06 21:18:37,837][root][INFO] - Questions selected, dataset contains 99 questions with 14.142857142857142 questions per domain
[2025-03-06 21:18:38,014][root][INFO] - Loading model : meta-llama/Llama-2-7b-hf
[2025-03-06 21:18:38,449][root][INFO] - Full model selected, loading model
[2025-03-06 21:18:57,480][root][INFO] - Tokenizer special tokens: {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'} have been added
[2025-03-06 21:20:00,258][root][INFO] - Fine-tuned model selected, loading adapter
[2025-03-06 21:20:00,273][root][WARNING] - Inference will be done using model.generate instead of hf pipeline since peft model is not compatible with it
[2025-03-06 21:20:27,803][root][INFO] - Peft model loaded successfully
[2025-03-06 21:20:34,008][root][INFO] - Prompt Handler initialized with configuration: {'prompt_type': 'zero_shot', 'example_path': '${hydra:runtime.cwd}/prompt/examples/structured_example.json', 'explanation_type': 'structured', 'response_type': 'fact_first', 'response_format': 'json', 'store_prompt': False, 'include_system_prompt': True, 'system_prompt': '${hydra:runtime.cwd}/prompt/system_prompt/system_${eval.prompt.response_format}_${eval.prompt.response_type}_${eval.prompt.explanation_type}.txt'}
[2025-03-06 21:20:34,010][root][INFO] - Raw output for this run will be saved to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/model_outputs/raw_responses/llama2/seed_206/all_domains_10_samples/trained_full_model/greedy/json_fact_first_zero_shot_structured/test_set_1.json
[2025-03-06 21:20:34,010][root][INFO] - Starting inference
[2025-03-06 21:20:34,485][root][INFO] - Processing question number 0
[2025-03-06 21:20:34,487][root][INFO] - Domain : Civil_procedure, Question : 1
[2025-03-06 21:20:47,277][root][INFO] - Domain : Civil_procedure, Question : 7
[2025-03-06 21:21:00,230][root][INFO] - Domain : Civil_procedure, Question : 14
[2025-03-06 21:21:15,276][root][INFO] - Domain : Civil_procedure, Question : 21
[2025-03-06 21:21:28,329][root][INFO] - Domain : Civil_procedure, Question : 28
[2025-03-06 21:21:41,398][root][INFO] - Domain : Civil_procedure, Question : 35
[2025-03-06 21:21:55,583][root][INFO] - Domain : Civil_procedure, Question : 42
[2025-03-06 21:22:09,494][root][INFO] - Domain : Civil_procedure, Question : 49
[2025-03-06 21:22:25,995][root][INFO] - Domain : Civil_procedure, Question : 56
[2025-03-06 21:22:38,689][root][INFO] - Domain : Civil_procedure, Question : 63
[2025-03-06 21:22:55,540][root][INFO] - Processing question number 10
[2025-03-06 21:22:55,541][root][INFO] - Domain : Civil_procedure, Question : 69
[2025-03-06 21:23:12,328][root][INFO] - Domain : Civil_procedure, Question : 70
[2025-03-06 21:23:25,567][root][INFO] - Domain : Civil_procedure, Question : 77
[2025-03-06 21:23:40,724][root][INFO] - Domain : Civil_procedure, Question : 84
[2025-03-06 21:23:54,754][root][INFO] - Domain : Civil_procedure, Question : 91
[2025-03-06 21:24:09,489][root][INFO] - Domain : Civil_procedure, Question : 98
[2025-03-06 21:24:22,718][root][INFO] - Domain : Constitutional_law, Question : 2
[2025-03-06 21:24:37,113][root][INFO] - Domain : Constitutional_law, Question : 9
[2025-03-06 21:24:51,185][root][INFO] - Domain : Constitutional_law, Question : 17
[2025-03-06 21:25:05,467][root][INFO] - Domain : Constitutional_law, Question : 25
[2025-03-06 21:25:17,340][root][INFO] - Processing question number 20
[2025-03-06 21:25:17,342][root][INFO] - Domain : Constitutional_law, Question : 29
[2025-03-06 21:25:30,121][root][INFO] - Domain : Constitutional_law, Question : 37
[2025-03-06 21:25:44,705][root][INFO] - Domain : Constitutional_law, Question : 43
[2025-03-06 21:25:56,002][root][INFO] - Domain : Constitutional_law, Question : 55
[2025-03-06 21:26:10,050][root][INFO] - Domain : Constitutional_law, Question : 60
[2025-03-06 21:26:23,005][root][INFO] - Domain : Constitutional_law, Question : 65
[2025-03-06 21:26:35,335][root][INFO] - Domain : Constitutional_law, Question : 71
[2025-03-06 21:26:48,903][root][INFO] - Domain : Constitutional_law, Question : 79
[2025-03-06 21:27:04,675][root][INFO] - Domain : Constitutional_law, Question : 87
[2025-03-06 21:27:16,821][root][INFO] - Domain : Constitutional_law, Question : 93
[2025-03-06 21:27:29,818][root][INFO] - Processing question number 30
[2025-03-06 21:27:29,820][root][INFO] - Domain : Contracts, Question : 3
[2025-03-06 21:27:45,955][root][INFO] - Domain : Contracts, Question : 8
[2025-03-06 21:28:00,384][root][INFO] - Domain : Contracts, Question : 16
[2025-03-06 21:28:12,317][root][INFO] - Domain : Contracts, Question : 22
[2025-03-06 21:28:25,917][root][INFO] - Domain : Contracts, Question : 27
[2025-03-06 21:28:36,494][root][INFO] - Domain : Contracts, Question : 38
[2025-03-06 21:28:51,288][root][INFO] - Domain : Contracts, Question : 46
[2025-03-06 21:29:01,588][root][INFO] - Domain : Contracts, Question : 51
[2025-03-06 21:29:16,999][root][INFO] - Domain : Contracts, Question : 58
[2025-03-06 21:29:31,300][root][INFO] - Domain : Contracts, Question : 66
[2025-03-06 21:29:49,762][root][INFO] - Processing question number 40
[2025-03-06 21:29:49,765][root][INFO] - Domain : Contracts, Question : 72
[2025-03-06 21:30:02,990][root][INFO] - Domain : Contracts, Question : 81
[2025-03-06 21:30:20,189][root][INFO] - Domain : Contracts, Question : 88
[2025-03-06 21:30:35,695][root][INFO] - Domain : Contracts, Question : 94
[2025-03-06 21:30:52,841][root][INFO] - Domain : Torts, Question : 4
[2025-03-06 21:31:06,746][root][INFO] - Domain : Torts, Question : 11
[2025-03-06 21:31:20,826][root][INFO] - Domain : Torts, Question : 24
[2025-03-06 21:31:35,783][root][INFO] - Domain : Torts, Question : 32
[2025-03-06 21:31:48,355][root][INFO] - Domain : Torts, Question : 41
[2025-03-06 21:32:01,369][root][INFO] - Domain : Torts, Question : 47
[2025-03-06 21:32:18,982][root][INFO] - Processing question number 50
[2025-03-06 21:32:18,994][root][INFO] - Domain : Torts, Question : 52
[2025-03-06 21:32:39,020][root][INFO] - Domain : Torts, Question : 62
[2025-03-06 21:32:58,031][root][INFO] - Domain : Torts, Question : 76
[2025-03-06 21:33:12,889][root][INFO] - Domain : Torts, Question : 82
[2025-03-06 21:33:26,396][root][INFO] - Domain : Torts, Question : 90
[2025-03-06 21:33:43,632][root][INFO] - Domain : Torts, Question : 95
[2025-03-06 21:33:56,501][root][INFO] - Domain : Torts, Question : 99
[2025-03-06 21:34:13,786][root][INFO] - Domain : Evidence, Question : 5
[2025-03-06 21:34:26,784][root][INFO] - Domain : Evidence, Question : 12
[2025-03-06 21:34:41,454][root][INFO] - Domain : Evidence, Question : 18
[2025-03-06 21:35:02,815][root][INFO] - Processing question number 60
[2025-03-06 21:35:02,818][root][INFO] - Domain : Evidence, Question : 23
[2025-03-06 21:35:16,522][root][INFO] - Domain : Evidence, Question : 31
[2025-03-06 21:35:29,214][root][INFO] - Domain : Evidence, Question : 34
[2025-03-06 21:35:43,265][root][INFO] - Domain : Evidence, Question : 40
[2025-03-06 21:35:56,061][root][INFO] - Domain : Evidence, Question : 44
[2025-03-06 21:36:07,424][root][INFO] - Domain : Evidence, Question : 53
[2025-03-06 21:36:22,933][root][INFO] - Domain : Evidence, Question : 59
[2025-03-06 21:36:38,231][root][INFO] - Domain : Evidence, Question : 68
[2025-03-06 21:36:51,097][root][INFO] - Domain : Evidence, Question : 73
[2025-03-06 21:37:06,524][root][INFO] - Domain : Evidence, Question : 78
[2025-03-06 21:37:23,952][root][INFO] - Processing question number 70
[2025-03-06 21:37:23,956][root][INFO] - Domain : Evidence, Question : 86
[2025-03-06 21:37:36,244][root][INFO] - Domain : Evidence, Question : 96
[2025-03-06 21:37:50,912][root][INFO] - Domain : Property, Question : 6
[2025-03-06 21:38:04,601][root][INFO] - Domain : Property, Question : 13
[2025-03-06 21:38:18,373][root][INFO] - Domain : Property, Question : 20
[2025-03-06 21:38:33,324][root][INFO] - Domain : Property, Question : 33
[2025-03-06 21:38:47,043][root][INFO] - Domain : Property, Question : 39
[2025-03-06 21:39:00,761][root][INFO] - Domain : Property, Question : 48
[2025-03-06 21:39:17,342][root][INFO] - Domain : Property, Question : 54
[2025-03-06 21:39:32,944][root][INFO] - Domain : Property, Question : 61
[2025-03-06 21:39:46,455][root][INFO] - Processing question number 80
[2025-03-06 21:39:46,459][root][INFO] - Domain : Property, Question : 67
[2025-03-06 21:40:02,154][root][INFO] - Domain : Property, Question : 75
[2025-03-06 21:40:17,222][root][INFO] - Domain : Property, Question : 83
[2025-03-06 21:40:29,381][root][INFO] - Domain : Property, Question : 89
[2025-03-06 21:40:42,520][root][INFO] - Domain : Property, Question : 97
[2025-03-06 21:40:54,522][root][INFO] - Domain : Property, Question : 100
[2025-03-06 21:41:08,979][root][INFO] - Domain : Criminal_law, Question : 10
[2025-03-06 21:41:22,830][root][INFO] - Domain : Criminal_law, Question : 15
[2025-03-06 21:41:36,840][root][INFO] - Domain : Criminal_law, Question : 26
[2025-03-06 21:41:51,862][root][INFO] - Domain : Criminal_law, Question : 30
[2025-03-06 21:42:05,264][root][INFO] - Processing question number 90
[2025-03-06 21:42:05,268][root][INFO] - Domain : Criminal_law, Question : 36
[2025-03-06 21:42:20,058][root][INFO] - Domain : Criminal_law, Question : 45
[2025-03-06 21:42:32,481][root][INFO] - Domain : Criminal_law, Question : 50
[2025-03-06 21:42:47,644][root][INFO] - Domain : Criminal_law, Question : 57
[2025-03-06 21:43:01,266][root][INFO] - Domain : Criminal_law, Question : 64
[2025-03-06 21:43:14,066][root][INFO] - Domain : Criminal_law, Question : 74
[2025-03-06 21:43:26,518][root][INFO] - Domain : Criminal_law, Question : 80
[2025-03-06 21:43:38,404][root][INFO] - Domain : Criminal_law, Question : 85
[2025-03-06 21:43:52,580][root][INFO] - Domain : Criminal_law, Question : 92
[2025-03-06 21:44:07,577][root][INFO] - Inference complete
[2025-03-06 21:44:07,577][root][INFO] - Saving raw outputs to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/model_outputs/raw_responses/llama2/seed_206/all_domains_10_samples/trained_full_model/greedy/json_fact_first_zero_shot_structured/test_set_1.json
[2025-03-06 21:44:07,582][root][INFO] - Starting parsing of raw outputs to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/model_outputs/parsed_responses/llama2/seed_206/all_domains_10_samples/trained_full_model/greedy/json_fact_first_zero_shot_structured/test_set_1.json
[2025-03-06 21:44:07,584][root][WARNING] - |Q. 56||D: Civil_procedure| has broken JSON output. Attempting to fix it.
[2025-03-06 21:44:07,585][root][WARNING] - |Q. 56||D: Civil_procedure| Successfully fixed invalid JSON. Not all fields may be present.
[2025-03-06 21:44:07,585][root][INFO] - |Q. 56||D: Civil_procedure| was made valid into Valid json. Extracting responses.
[2025-03-06 21:44:07,585][root][WARNING] - |Q. 63||D: Civil_procedure| has broken JSON output. Attempting to fix it.
[2025-03-06 21:44:07,585][root][WARNING] - |Q. 63||D: Civil_procedure| Successfully fixed invalid JSON. Not all fields may be present.
[2025-03-06 21:44:07,585][root][INFO] - |Q. 63||D: Civil_procedure| was made valid into Valid json. Extracting responses.
[2025-03-06 21:44:07,586][root][WARNING] - |Q. 70||D: Civil_procedure| has broken JSON output. Attempting to fix it.
[2025-03-06 21:44:07,586][root][WARNING] - |Q. 70||D: Civil_procedure| Successfully fixed invalid JSON. Not all fields may be present.
[2025-03-06 21:44:07,586][root][INFO] - |Q. 70||D: Civil_procedure| was made valid into Valid json. Extracting responses.
[2025-03-06 21:44:07,596][root][INFO] - Saving parsed outputs to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/model_outputs/parsed_responses/llama2/seed_206/all_domains_10_samples/trained_full_model/greedy/json_fact_first_zero_shot_structured/test_set_1.json
[2025-03-06 21:44:07,601][root][INFO] - Dumped the response to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/model_outputs/parsed_responses/llama2/seed_206/all_domains_10_samples/trained_full_model/greedy/json_fact_first_zero_shot_structured/test_set_1.json
[2025-03-06 21:44:07,601][root][INFO] - Saved parsed outputs
[2025-03-06 21:44:07,601][root][INFO] - Saving parsing metadata to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/parsing_metadata/raw_responses/llama2/seed_206/all_domains_10_samples/trained_full_model/greedy/json_fact_first_zero_shot_structured/test_set_1.json
[2025-03-06 21:44:07,602][root][INFO] - Dumped the stats to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/parsing_metadata/raw_responses/llama2/seed_206/all_domains_10_samples/trained_full_model/greedy/json_fact_first_zero_shot_structured/test_set_1.json
[2025-03-06 21:44:07,602][root][INFO] - Saved parsing metadata
[2025-03-06 21:44:07,603][root][INFO] - Metrics will be saved to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/model_outputs/metrics/llama2/seed_206/all_domains_10_samples/trained_full_model/greedy/json_fact_first_zero_shot_structured/test_set_1.json
[2025-03-06 21:44:07,605][root][INFO] - Metrics calculated, saving backup to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/model_outputs/metrics/llama2/seed_206/all_domains_10_samples/trained_full_model/greedy/json_fact_first_zero_shot_structured/test_set_1.json
[2025-03-06 21:44:07,607][root][INFO] - Dumped the metrics to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/model_outputs/metrics/llama2/seed_206/all_domains_10_samples/trained_full_model/greedy/json_fact_first_zero_shot_structured/test_set_1.json
Metrics successfully appended to master CSV.
[2025-03-06 21:44:07,634][root][INFO] - Evaluation completed for json_fact_first_zero_shot_structured, on test_set_1
[2025-03-06 21:44:07,634][root][INFO] - Summary of metrics : {'label_accuracy': 0.32323232323232326, 'misclassification_rate': 0.6767676767676767, 'combined_accuracy': 0.2828282828282828, 'malformed_label': 3, 'malformed_domain': 15, 'total_predictions': 99, 'correct_predictions': 32, 'correct_label_and_domain': 28, 'Constitutional_Law_accuracy': 0.21428571428571427, 'Contracts_accuracy': 0.2857142857142857, 'Criminal_Law_accuracy': 0.3076923076923077, 'Evidence_accuracy': 0.13333333333333333, 'Real_Property_accuracy': 0.42857142857142855, 'Torts_accuracy': 0.38461538461538464, 'Civil_Procedure_accuracy': 0.25, 'Constitutional_Law_confidence': 0.1414141414141414, 'Contracts_confidence': 0.1919191919191919, 'Criminal_Law_confidence': 0.1111111111111111, 'Evidence_confidence': 0.12121212121212122, 'Real_Property_confidence': 0.10101010101010101, 'Torts_confidence': 0.16161616161616163, 'Civil_Procedure_confidence': 0.16161616161616163, 'correct_domain_wrong_label': 56, 'correct_label_wrong_domain': 4, 'both_wrong': 11}
Starting update_eval_status.py
Received arguments: ['/pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/scripts/update_eval_status.py', '29', 'seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_10_samples generation=greedy evaluation_dataset=test_set_1 eval=json_fact_first_zero_shot_structured ++eval.quantisation_status=full_model ++eval.training_status=trained', 'completed', '0']
Updating eval for job 29 to status completed with exit code 0
Eval status update completed for job 29
Running evaluation with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_10_samples generation=temp_025 evaluation_dataset=test_set_1 eval=json_fact_first_zero_shot_structured ++eval.quantisation_status=full_model ++eval.training_status=trained
Starting update_eval_status.py
Received arguments: ['/pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/scripts/update_eval_status.py', '29', 'seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_10_samples generation=temp_025 evaluation_dataset=test_set_1 eval=json_fact_first_zero_shot_structured ++eval.quantisation_status=full_model ++eval.training_status=trained', 'running']
Updating eval for job 29 to status running with exit code None
Eval status update completed for job 29
[2025-03-06 21:44:18,539][root][INFO] - Setting global seed to 206
[2025-03-06 21:44:18,546][root][INFO] - Running evaluation of the trained model on the test_set_1
[2025-03-06 21:44:18,547][root][INFO] - Current evaluation config is : 
 Prompt type : zero_shot 
 Response type : fact_first 
 Explanation type : structured 
 Response Format : json 
[2025-03-06 21:44:18,548][root][INFO] - Loading dataset from /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/dataset/test_sets/bar_set_1.json
[2025-03-06 21:44:18,550][root][INFO] - Dataset loaded successfully, indexing questions...
[2025-03-06 21:44:18,552][root][INFO] - Indexing complete, sampling of questions set to False
[2025-03-06 21:44:18,552][root][INFO] - Questions selected, dataset contains 99 questions with 14.142857142857142 questions per domain
[2025-03-06 21:44:18,711][root][INFO] - Loading model : meta-llama/Llama-2-7b-hf
[2025-03-06 21:44:18,968][root][INFO] - Full model selected, loading model
[2025-03-06 21:44:36,869][root][INFO] - Tokenizer special tokens: {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'} have been added
[2025-03-06 21:45:36,007][root][INFO] - Fine-tuned model selected, loading adapter
[2025-03-06 21:45:36,007][root][WARNING] - Inference will be done using model.generate instead of hf pipeline since peft model is not compatible with it
[2025-03-06 21:46:00,787][root][INFO] - Peft model loaded successfully
[2025-03-06 21:46:06,883][root][INFO] - Prompt Handler initialized with configuration: {'prompt_type': 'zero_shot', 'example_path': '${hydra:runtime.cwd}/prompt/examples/structured_example.json', 'explanation_type': 'structured', 'response_type': 'fact_first', 'response_format': 'json', 'store_prompt': False, 'include_system_prompt': True, 'system_prompt': '${hydra:runtime.cwd}/prompt/system_prompt/system_${eval.prompt.response_format}_${eval.prompt.response_type}_${eval.prompt.explanation_type}.txt'}
[2025-03-06 21:46:06,884][root][INFO] - Raw output for this run will be saved to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/model_outputs/raw_responses/llama2/seed_206/all_domains_10_samples/trained_full_model/temp_025/json_fact_first_zero_shot_structured/test_set_1.json
[2025-03-06 21:46:06,885][root][INFO] - Starting inference
[2025-03-06 21:46:07,107][root][INFO] - Processing question number 0
[2025-03-06 21:46:07,109][root][INFO] - Domain : Civil_procedure, Question : 1
[2025-03-06 21:46:20,410][root][INFO] - Domain : Civil_procedure, Question : 7
[2025-03-06 21:46:33,796][root][INFO] - Domain : Civil_procedure, Question : 14
[2025-03-06 21:46:46,029][root][INFO] - Domain : Civil_procedure, Question : 21
[2025-03-06 21:47:00,454][root][INFO] - Domain : Civil_procedure, Question : 28
[2025-03-06 21:47:13,430][root][INFO] - Domain : Civil_procedure, Question : 35
[2025-03-06 21:47:27,707][root][INFO] - Domain : Civil_procedure, Question : 42
[2025-03-06 21:47:42,069][root][INFO] - Domain : Civil_procedure, Question : 49
[2025-03-06 21:47:55,922][root][INFO] - Domain : Civil_procedure, Question : 56
[2025-03-06 21:48:11,117][root][INFO] - Domain : Civil_procedure, Question : 63
[2025-03-06 21:48:27,802][root][INFO] - Processing question number 10
[2025-03-06 21:48:27,804][root][INFO] - Domain : Civil_procedure, Question : 69
[2025-03-06 21:48:45,826][root][INFO] - Domain : Civil_procedure, Question : 70
[2025-03-06 21:48:59,749][root][INFO] - Domain : Civil_procedure, Question : 77
[2025-03-06 21:49:16,291][root][INFO] - Domain : Civil_procedure, Question : 84
[2025-03-06 21:49:29,067][root][INFO] - Domain : Civil_procedure, Question : 91
[2025-03-06 21:49:43,083][root][INFO] - Domain : Civil_procedure, Question : 98
[2025-03-06 21:49:56,744][root][INFO] - Domain : Constitutional_law, Question : 2
[2025-03-06 21:50:10,802][root][INFO] - Domain : Constitutional_law, Question : 9
[2025-03-06 21:50:24,260][root][INFO] - Domain : Constitutional_law, Question : 17
