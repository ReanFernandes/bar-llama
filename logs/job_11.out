Starting job 11 at Do 20. Feb 10:02:32 CET 2025
Configuration: model=llama2 tokenizer=llama2 dataset=all_domains_1_samples prompt=number_list_fact_first_few_shot_unstructured train=number_list_fact_first_few_shot_unstructured ++train.training_args.per_device_train_batch_size=7 ++train.training_args.gradient_accumulation_steps=1
[2025-02-20 10:02:50,181][root][INFO] - Global seed set to 314
[2025-02-20 10:02:50,183][root][WARNING] - Quantisation will be done on loaded model, THIS IS A QLORA FINE-TUNING RUN
[2025-02-20 10:02:50,183][root][WARNING] - Following flags are set for the run : 
 Use Quantisation before fine-tuning : True 
 Perform Validation on epoch end : False
[2025-02-20 10:02:50,183][root][INFO] - Running Fine-tuning on the all_domains_1_samples dataset
[2025-02-20 10:02:50,183][root][INFO] - Current training config is : 
 Prompt type : few_shot 
 Response type : fact_first 
 Explanation type : unstructured 
 Response Format : number_list 
[2025-02-20 10:02:50,183][root][INFO] - Loading dataset from /home/fr/fr_fr/fr_rf1031/bar-llama/dataset/seed_dataset/raw_dataset.json
[2025-02-20 10:02:50,200][root][INFO] - Dataset loaded successfully, indexing questions...
[2025-02-20 10:02:50,253][root][INFO] - Indexing complete, sampling of questions set to True
[2025-02-20 10:02:50,256][root][INFO] - Questions selected, dataset contains 7 questions with 1.0 questions per domain
[2025-02-20 10:02:50,292][root][INFO] - Prompt Handler initialized with configuration: {'prompt_type': 'few_shot', 'example_path': '${hydra:runtime.cwd}/prompt/examples/unstructured_example.json', 'explanation_type': 'unstructured', 'response_type': 'fact_first', 'response_format': 'number_list', 'store_prompt': True, 'system_prompt': '${hydra:runtime.cwd}/prompt/system_prompt/system_${train.prompt.response_format}_${train.prompt.response_type}_${train.prompt.explanation_type}.txt', 'include_system_prompt': True}
[2025-02-20 10:02:50,703][root][INFO] - Tokenizer meta-llama/Llama-2-7b-hf loaded successfully
[2025-02-20 10:03:05,425][root][INFO] - Quantised model meta-llama/Llama-2-7b-hf loaded successfully
[2025-02-20 10:03:34,833][root][INFO] - Model prepared for kbit training
[2025-02-20 10:03:34,833][root][INFO] - Lora config loaded, following are the details : 
 LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=64, target_modules={'gate_proj', 'v_proj', 'down_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj'}, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))
[2025-02-20 10:03:36,558][root][INFO] - Lora adapter added to model
[2025-02-20 10:03:36,560][root][INFO] - Model adapter will be saved to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/sft_adapters/llama2/all_domains_1_samples/llama2_number_list_fact_first_few_shot_unstructured
[2025-02-20 10:03:36,659][accelerate.utils.other][WARNING] - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'loss': 1.376, 'grad_norm': 0.22256989777088165, 'learning_rate': 3.226975564787322e-05, 'epoch': 10.0}
{'train_runtime': 382.6247, 'train_samples_per_second': 0.274, 'train_steps_per_second': 0.039, 'train_loss': 1.262788963317871, 'epoch': 15.0}
[2025-02-20 10:10:02,305][root][INFO] - Finetuning complete, model saved to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/sft_adapters/llama2/all_domains_1_samples/llama2_number_list_fact_first_few_shot_unstructured
Starting evaluations for job 11
Running evaluation with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=greedy evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
[2025-02-20 10:10:11,643][root][INFO] - Setting global seed to 206
[2025-02-20 10:10:11,648][root][INFO] - Running evaluation of the trained model on the test_set_1
[2025-02-20 10:10:11,648][root][INFO] - Current evaluation config is : 
 Prompt type : few_shot 
 Response type : fact_first 
 Explanation type : unstructured 
 Response Format : number_list 
[2025-02-20 10:10:11,650][root][INFO] - Loading dataset from /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/dataset/test_sets/bar_set_1.json
[2025-02-20 10:10:11,651][root][INFO] - Dataset loaded successfully, indexing questions...
[2025-02-20 10:10:11,653][root][INFO] - Indexing complete, sampling of questions set to False
[2025-02-20 10:10:11,653][root][INFO] - Questions selected, dataset contains 99 questions with 14.142857142857142 questions per domain
[2025-02-20 10:10:11,813][root][INFO] - Loading model : meta-llama/Llama-2-7b-hf
[2025-02-20 10:10:12,066][root][INFO] - Full model selected, loading model
[2025-02-20 10:10:24,048][root][INFO] - Tokenizer special tokens: {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'} have been added
[2025-02-20 10:11:27,980][root][INFO] - Fine-tuned model selected, loading adapter
[2025-02-20 10:11:27,981][root][WARNING] - Inference will be done using model.generate instead of hf pipeline since peft model is not compatible with it
[2025-02-20 10:11:54,404][root][INFO] - Peft model loaded successfully
[2025-02-20 10:12:00,570][root][INFO] - Prompt Handler initialized with configuration: {'prompt_type': 'few_shot', 'example_path': '${hydra:runtime.cwd}/prompt/examples/unstructured_example.json', 'explanation_type': 'unstructured', 'response_type': 'fact_first', 'response_format': 'number_list', 'store_prompt': False, 'include_system_prompt': True, 'system_prompt': '${hydra:runtime.cwd}/prompt/system_prompt/system_${eval.prompt.response_format}_${eval.prompt.response_type}_${eval.prompt.explanation_type}.txt'}
[2025-02-20 10:12:00,571][root][INFO] - Raw output for this run will be saved to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/model_outputs/raw_responses/llama2/seed_206/all_domains_1_samples/trained_full_model/greedy/number_list_fact_first_few_shot_unstructured/test_set_1.json
[2025-02-20 10:12:00,571][root][INFO] - Starting inference
[2025-02-20 10:12:00,759][root][INFO] - Processing question number 0
[2025-02-20 10:12:00,762][root][INFO] - Domain : Civil_procedure, Question : 1
[2025-02-20 10:12:30,101][root][INFO] - Domain : Civil_procedure, Question : 7
[2025-02-20 10:13:00,426][root][INFO] - Domain : Civil_procedure, Question : 14
[2025-02-20 10:13:30,245][root][INFO] - Domain : Civil_procedure, Question : 21
[2025-02-20 10:14:00,544][root][INFO] - Domain : Civil_procedure, Question : 28
[2025-02-20 10:14:30,221][root][INFO] - Domain : Civil_procedure, Question : 35
[2025-02-20 10:14:59,843][root][INFO] - Domain : Civil_procedure, Question : 42
[2025-02-20 10:15:30,241][root][INFO] - Domain : Civil_procedure, Question : 49
[2025-02-20 10:16:00,195][root][INFO] - Domain : Civil_procedure, Question : 56
[2025-02-20 10:16:29,791][root][INFO] - Domain : Civil_procedure, Question : 63
[2025-02-20 10:17:00,073][root][INFO] - Processing question number 10
[2025-02-20 10:17:00,074][root][INFO] - Domain : Civil_procedure, Question : 69
[2025-02-20 10:17:31,696][root][INFO] - Domain : Civil_procedure, Question : 70
[2025-02-20 10:18:01,115][root][INFO] - Domain : Civil_procedure, Question : 77
[2025-02-20 10:18:31,039][root][INFO] - Domain : Civil_procedure, Question : 84
[2025-02-20 10:19:01,572][root][INFO] - Domain : Civil_procedure, Question : 91
[2025-02-20 10:19:32,045][root][INFO] - Domain : Civil_procedure, Question : 98
[2025-02-20 10:20:01,515][root][INFO] - Domain : Constitutional_law, Question : 2
[2025-02-20 10:20:30,912][root][INFO] - Domain : Constitutional_law, Question : 9
[2025-02-20 10:21:00,779][root][INFO] - Domain : Constitutional_law, Question : 17
[2025-02-20 10:21:30,638][root][INFO] - Domain : Constitutional_law, Question : 25
[2025-02-20 10:22:00,230][root][INFO] - Processing question number 20
[2025-02-20 10:22:00,233][root][INFO] - Domain : Constitutional_law, Question : 29
[2025-02-20 10:22:30,067][root][INFO] - Domain : Constitutional_law, Question : 37
[2025-02-20 10:23:00,079][root][INFO] - Domain : Constitutional_law, Question : 43
[2025-02-20 10:23:29,544][root][INFO] - Domain : Constitutional_law, Question : 55
[2025-02-20 10:23:58,952][root][INFO] - Domain : Constitutional_law, Question : 60
[2025-02-20 10:24:29,057][root][INFO] - Domain : Constitutional_law, Question : 65
[2025-02-20 10:24:58,959][root][INFO] - Domain : Constitutional_law, Question : 71
[2025-02-20 10:25:29,647][root][INFO] - Domain : Constitutional_law, Question : 79
[2025-02-20 10:25:59,493][root][INFO] - Domain : Constitutional_law, Question : 87
[2025-02-20 10:26:29,477][root][INFO] - Domain : Constitutional_law, Question : 93
[2025-02-20 10:26:58,723][root][INFO] - Processing question number 30
[2025-02-20 10:26:58,726][root][INFO] - Domain : Contracts, Question : 3
[2025-02-20 10:27:28,889][root][INFO] - Domain : Contracts, Question : 8
[2025-02-20 10:27:59,359][root][INFO] - Domain : Contracts, Question : 16
[2025-02-20 10:28:29,328][root][INFO] - Domain : Contracts, Question : 22
[2025-02-20 10:28:59,147][root][INFO] - Domain : Contracts, Question : 27
[2025-02-20 10:29:28,820][root][INFO] - Domain : Contracts, Question : 38
[2025-02-20 10:29:59,214][root][INFO] - Domain : Contracts, Question : 46
[2025-02-20 10:30:29,005][root][INFO] - Domain : Contracts, Question : 51
[2025-02-20 10:30:59,178][root][INFO] - Domain : Contracts, Question : 58
[2025-02-20 10:31:29,145][root][INFO] - Domain : Contracts, Question : 66
[2025-02-20 10:31:59,852][root][INFO] - Processing question number 40
[2025-02-20 10:31:59,855][root][INFO] - Domain : Contracts, Question : 72
[2025-02-20 10:32:29,867][root][INFO] - Domain : Contracts, Question : 81
[2025-02-20 10:32:59,870][root][INFO] - Domain : Contracts, Question : 88
[2025-02-20 10:33:30,345][root][INFO] - Domain : Contracts, Question : 94
[2025-02-20 10:34:00,766][root][INFO] - Domain : Torts, Question : 4
[2025-02-20 10:34:30,457][root][INFO] - Domain : Torts, Question : 11
[2025-02-20 10:35:00,445][root][INFO] - Domain : Torts, Question : 24
[2025-02-20 10:35:31,833][root][INFO] - Domain : Torts, Question : 32
[2025-02-20 10:36:01,087][root][INFO] - Domain : Torts, Question : 41
[2025-02-20 10:36:30,970][root][INFO] - Domain : Torts, Question : 47
[2025-02-20 10:37:01,586][root][INFO] - Processing question number 50
[2025-02-20 10:37:01,590][root][INFO] - Domain : Torts, Question : 52
[2025-02-20 10:37:32,483][root][INFO] - Domain : Torts, Question : 62
[2025-02-20 10:38:02,592][root][INFO] - Domain : Torts, Question : 76
[2025-02-20 10:38:31,960][root][INFO] - Domain : Torts, Question : 82
[2025-02-20 10:39:02,995][root][INFO] - Domain : Torts, Question : 90
[2025-02-20 10:39:33,070][root][INFO] - Domain : Torts, Question : 95
[2025-02-20 10:40:02,175][root][INFO] - Domain : Torts, Question : 99
[2025-02-20 10:40:32,903][root][INFO] - Domain : Evidence, Question : 5
[2025-02-20 10:41:02,415][root][INFO] - Domain : Evidence, Question : 12
[2025-02-20 10:41:32,945][root][INFO] - Domain : Evidence, Question : 18
[2025-02-20 10:42:04,308][root][INFO] - Processing question number 60
[2025-02-20 10:42:04,314][root][INFO] - Domain : Evidence, Question : 23
[2025-02-20 10:42:33,805][root][INFO] - Domain : Evidence, Question : 31
[2025-02-20 10:43:03,653][root][INFO] - Domain : Evidence, Question : 34
[2025-02-20 10:43:34,093][root][INFO] - Domain : Evidence, Question : 40
[2025-02-20 10:44:03,561][root][INFO] - Domain : Evidence, Question : 44
[2025-02-20 10:44:33,531][root][INFO] - Domain : Evidence, Question : 53
[2025-02-20 10:45:03,545][root][INFO] - Domain : Evidence, Question : 59
[2025-02-20 10:45:33,574][root][INFO] - Domain : Evidence, Question : 68
[2025-02-20 10:46:03,918][root][INFO] - Domain : Evidence, Question : 73
[2025-02-20 10:46:34,034][root][INFO] - Domain : Evidence, Question : 78
[2025-02-20 10:47:04,672][root][INFO] - Processing question number 70
[2025-02-20 10:47:04,677][root][INFO] - Domain : Evidence, Question : 86
[2025-02-20 10:47:34,485][root][INFO] - Domain : Evidence, Question : 96
[2025-02-20 10:48:04,325][root][INFO] - Domain : Property, Question : 6
[2025-02-20 10:48:34,000][root][INFO] - Domain : Property, Question : 13
[2025-02-20 10:49:04,311][root][INFO] - Domain : Property, Question : 20
[2025-02-20 10:49:34,580][root][INFO] - Domain : Property, Question : 33
[2025-02-20 10:50:04,124][root][INFO] - Domain : Property, Question : 39
[2025-02-20 10:50:34,483][root][INFO] - Domain : Property, Question : 48
[2025-02-20 10:51:04,636][root][INFO] - Domain : Property, Question : 54
[2025-02-20 10:51:35,003][root][INFO] - Domain : Property, Question : 61
[2025-02-20 10:52:04,806][root][INFO] - Processing question number 80
[2025-02-20 10:52:04,811][root][INFO] - Domain : Property, Question : 67
[2025-02-20 10:52:35,062][root][INFO] - Domain : Property, Question : 75
[2025-02-20 10:53:05,286][root][INFO] - Domain : Property, Question : 83
[2025-02-20 10:53:35,119][root][INFO] - Domain : Property, Question : 89
[2025-02-20 10:54:05,084][root][INFO] - Domain : Property, Question : 97
[2025-02-20 10:54:35,720][root][INFO] - Domain : Property, Question : 100
[2025-02-20 10:55:06,207][root][INFO] - Domain : Criminal_law, Question : 10
[2025-02-20 10:55:36,729][root][INFO] - Domain : Criminal_law, Question : 15
[2025-02-20 10:56:06,532][root][INFO] - Domain : Criminal_law, Question : 26
[2025-02-20 10:56:36,672][root][INFO] - Domain : Criminal_law, Question : 30
[2025-02-20 10:57:06,132][root][INFO] - Processing question number 90
[2025-02-20 10:57:06,145][root][INFO] - Domain : Criminal_law, Question : 36
[2025-02-20 10:57:37,043][root][INFO] - Domain : Criminal_law, Question : 45
[2025-02-20 10:58:05,992][root][INFO] - Domain : Criminal_law, Question : 50
[2025-02-20 10:58:35,836][root][INFO] - Domain : Criminal_law, Question : 57
[2025-02-20 10:59:04,939][root][INFO] - Domain : Criminal_law, Question : 64
[2025-02-20 10:59:35,315][root][INFO] - Domain : Criminal_law, Question : 74
[2025-02-20 11:00:04,768][root][INFO] - Domain : Criminal_law, Question : 80
[2025-02-20 11:00:34,603][root][INFO] - Domain : Criminal_law, Question : 85
[2025-02-20 11:01:04,752][root][INFO] - Domain : Criminal_law, Question : 92
[2025-02-20 11:01:35,376][root][INFO] - Inference complete
[2025-02-20 11:01:35,376][root][INFO] - Saving raw outputs to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/model_outputs/raw_responses/llama2/seed_206/all_domains_1_samples/trained_full_model/greedy/number_list_fact_first_few_shot_unstructured/test_set_1.json
[2025-02-20 11:01:35,383][root][INFO] - Starting parsing of raw outputs to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/model_outputs/parsed_responses/llama2/seed_206/all_domains_1_samples/trained_full_model/greedy/number_list_fact_first_few_shot_unstructured/test_set_1.json
[2025-02-20 11:01:35,384][root][WARNING] - No match found for 3. Chosen Option Label in question number 7 in domain Civil_procedure
[2025-02-20 11:01:35,385][root][WARNING] - No match found for 3. Chosen Option Label in question number 28 in domain Civil_procedure
[2025-02-20 11:01:35,385][root][WARNING] - No match found for 3. Chosen Option Label in question number 49 in domain Civil_procedure
[2025-02-20 11:01:35,386][root][WARNING] - No match found for 3. Chosen Option Label in question number 56 in domain Civil_procedure
[2025-02-20 11:01:35,386][root][WARNING] - No match found for 3. Chosen Option Label in question number 63 in domain Civil_procedure
[2025-02-20 11:01:35,386][root][WARNING] - No match found for 3. Chosen Option Label in question number 69 in domain Civil_procedure
[2025-02-20 11:01:35,387][root][WARNING] - No match found for 3. Chosen Option Label in question number 77 in domain Civil_procedure
[2025-02-20 11:01:35,387][root][WARNING] - No match found for 3. Chosen Option Label in question number 91 in domain Civil_procedure
[2025-02-20 11:01:35,388][root][WARNING] - No match found for 3. Chosen Option Label in question number 17 in domain Constitutional_law
[2025-02-20 11:01:35,388][root][WARNING] - No match found for 3. Chosen Option Label in question number 25 in domain Constitutional_law
[2025-02-20 11:01:35,388][root][WARNING] - No match found for 3. Chosen Option Label in question number 37 in domain Constitutional_law
[2025-02-20 11:01:35,389][root][WARNING] - No match found for 3. Chosen Option Label in question number 87 in domain Constitutional_law
[2025-02-20 11:01:35,389][root][WARNING] - No match found for 3. Chosen Option Label in question number 93 in domain Constitutional_law
[2025-02-20 11:01:35,390][root][WARNING] - No match found for 3. Chosen Option Label in question number 3 in domain Contracts
[2025-02-20 11:01:35,390][root][WARNING] - No match found for 3. Chosen Option Label in question number 16 in domain Contracts
[2025-02-20 11:01:35,391][root][WARNING] - No match found for 3. Chosen Option Label in question number 46 in domain Contracts
[2025-02-20 11:01:35,391][root][WARNING] - No match found for 3. Chosen Option Label in question number 51 in domain Contracts
[2025-02-20 11:01:35,391][root][WARNING] - No match found for 3. Chosen Option Label in question number 66 in domain Contracts
[2025-02-20 11:01:35,392][root][WARNING] - No match found for 3. Chosen Option Label in question number 88 in domain Contracts
[2025-02-20 11:01:35,392][root][WARNING] - No match found for 3. Chosen Option Label in question number 94 in domain Contracts
[2025-02-20 11:01:35,392][root][WARNING] - No match found for 3. Chosen Option Label in question number 4 in domain Torts
[2025-02-20 11:01:35,393][root][WARNING] - No match found for 3. Chosen Option Label in question number 11 in domain Torts
[2025-02-20 11:01:35,393][root][WARNING] - No match found for 3. Chosen Option Label in question number 41 in domain Torts
[2025-02-20 11:01:35,394][root][WARNING] - No match found for 3. Chosen Option Label in question number 47 in domain Torts
[2025-02-20 11:01:35,394][root][WARNING] - No match found for 3. Chosen Option Label in question number 52 in domain Torts
[2025-02-20 11:01:35,394][root][WARNING] - No match found for 3. Chosen Option Label in question number 90 in domain Torts
[2025-02-20 11:01:35,395][root][WARNING] - No match found for 3. Chosen Option Label in question number 18 in domain Evidence
[2025-02-20 11:01:35,395][root][WARNING] - No match found for 3. Chosen Option Label in question number 23 in domain Evidence
[2025-02-20 11:01:35,396][root][WARNING] - No match found for 3. Chosen Option Label in question number 34 in domain Evidence
[2025-02-20 11:01:35,396][root][WARNING] - No match found for 3. Chosen Option Label in question number 40 in domain Evidence
[2025-02-20 11:01:35,396][root][WARNING] - No match found for 3. Chosen Option Label in question number 44 in domain Evidence
[2025-02-20 11:01:35,397][root][WARNING] - No match found for 3. Chosen Option Label in question number 68 in domain Evidence
[2025-02-20 11:01:35,398][root][WARNING] - No match found for 3. Chosen Option Label in question number 6 in domain Property
[2025-02-20 11:01:35,398][root][WARNING] - No match found for 3. Chosen Option Label in question number 13 in domain Property
[2025-02-20 11:01:35,399][root][WARNING] - No match found for 3. Chosen Option Label in question number 48 in domain Property
[2025-02-20 11:01:35,399][root][WARNING] - No match found for 3. Chosen Option Label in question number 54 in domain Property
[2025-02-20 11:01:35,399][root][WARNING] - No match found for 3. Chosen Option Label in question number 75 in domain Property
[2025-02-20 11:01:35,400][root][WARNING] - No match found for 3. Chosen Option Label in question number 83 in domain Property
[2025-02-20 11:01:35,400][root][WARNING] - No match found for 3. Chosen Option Label in question number 89 in domain Property
[2025-02-20 11:01:35,400][root][WARNING] - No match found for 3. Chosen Option Label in question number 97 in domain Property
[2025-02-20 11:01:35,400][root][WARNING] - No match found for 3. Chosen Option Label in question number 10 in domain Criminal_law
[2025-02-20 11:01:35,401][root][WARNING] - No match found for 3. Chosen Option Label in question number 15 in domain Criminal_law
[2025-02-20 11:01:35,401][root][WARNING] - No match found for 3. Chosen Option Label in question number 30 in domain Criminal_law
[2025-02-20 11:01:35,401][root][WARNING] - No match found for 3. Chosen Option Label in question number 36 in domain Criminal_law
[2025-02-20 11:01:35,402][root][WARNING] - No match found for 3. Chosen Option Label in question number 57 in domain Criminal_law
[2025-02-20 11:01:35,402][root][WARNING] - No match found for 3. Chosen Option Label in question number 74 in domain Criminal_law
[2025-02-20 11:01:35,402][root][WARNING] - No match found for 3. Chosen Option Label in question number 80 in domain Criminal_law
[2025-02-20 11:01:35,404][root][INFO] - Saving parsed outputs to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/model_outputs/parsed_responses/llama2/seed_206/all_domains_1_samples/trained_full_model/greedy/number_list_fact_first_few_shot_unstructured/test_set_1.json
[2025-02-20 11:01:35,410][root][INFO] - Dumped the response to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/model_outputs/parsed_responses/llama2/seed_206/all_domains_1_samples/trained_full_model/greedy/number_list_fact_first_few_shot_unstructured/test_set_1.json
[2025-02-20 11:01:35,410][root][INFO] - Saved parsed outputs
[2025-02-20 11:01:35,410][root][INFO] - Saving parsing metadata to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/parsing_metadata/raw_responses/llama2/seed_206/all_domains_1_samples/trained_full_model/greedy/number_list_fact_first_few_shot_unstructured/test_set_1.json
[2025-02-20 11:01:35,411][root][INFO] - Dumped the stats to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/parsing_metadata/raw_responses/llama2/seed_206/all_domains_1_samples/trained_full_model/greedy/number_list_fact_first_few_shot_unstructured/test_set_1.json
[2025-02-20 11:01:35,411][root][INFO] - Saved parsing metadata
[2025-02-20 11:01:35,412][root][INFO] - Metrics will be saved to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/model_outputs/metrics/llama2/seed_206/all_domains_1_samples/trained_full_model/greedy/number_list_fact_first_few_shot_unstructured/test_set_1.json
[2025-02-20 11:01:35,414][root][INFO] - Metrics calculated, saving backup to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/model_outputs/metrics/llama2/seed_206/all_domains_1_samples/trained_full_model/greedy/number_list_fact_first_few_shot_unstructured/test_set_1.json
[2025-02-20 11:01:35,415][root][INFO] - Dumped the metrics to /pfs/work7/workspace/scratch/fr_rf1031-model_temp_storage/bar-llama/model_outputs/metrics/llama2/seed_206/all_domains_1_samples/trained_full_model/greedy/number_list_fact_first_few_shot_unstructured/test_set_1.json
Metrics successfully appended to master CSV.
[2025-02-20 11:01:35,427][root][INFO] - Evaluation completed for number_list_fact_first_few_shot_unstructured, on test_set_1
[2025-02-20 11:01:35,428][root][INFO] - Summary of metrics : {'label_accuracy': 0.25252525252525254, 'misclassification_rate': 0.7474747474747474, 'combined_accuracy': 0.2222222222222222, 'malformed_label': 47, 'malformed_domain': 21, 'total_predictions': 99, 'correct_predictions': 25, 'correct_label_and_domain': 22, 'Constitutional_Law_accuracy': 0.2857142857142857, 'Contracts_accuracy': 0.2857142857142857, 'Criminal_Law_accuracy': 0.15384615384615385, 'Evidence_accuracy': 0.13333333333333333, 'Real_Property_accuracy': 0.07142857142857142, 'Torts_accuracy': 0.3076923076923077, 'Civil_Procedure_accuracy': 0.3125, 'Constitutional_Law_confidence': 0.12121212121212122, 'Contracts_confidence': 0.1919191919191919, 'Criminal_Law_confidence': 0.1919191919191919, 'Evidence_confidence': 0.08080808080808081, 'Real_Property_confidence': 0.0707070707070707, 'Torts_confidence': 0.15151515151515152, 'Civil_Procedure_confidence': 0.12121212121212122, 'correct_domain_wrong_label': 56, 'correct_label_wrong_domain': 3, 'both_wrong': 18}
Running evaluation with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=greedy evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Evaluation failed with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=greedy evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Running evaluation with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_025 evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Evaluation failed with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_025 evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Running evaluation with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_025 evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Evaluation failed with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_025 evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Running evaluation with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_06 evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Evaluation failed with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_06 evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Running evaluation with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_06 evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Evaluation failed with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_06 evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Running evaluation with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=greedy evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Evaluation failed with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=greedy evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Running evaluation with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=greedy evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Evaluation failed with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=greedy evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Running evaluation with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_025 evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Evaluation failed with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_025 evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Running evaluation with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_025 evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Evaluation failed with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_025 evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Running evaluation with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_06 evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Evaluation failed with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_06 evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Running evaluation with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_06 evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Evaluation failed with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_06 evaluation_dataset=test_set_1 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Running evaluation with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=greedy evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Evaluation failed with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=greedy evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Running evaluation with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=greedy evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Evaluation failed with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=greedy evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Running evaluation with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_025 evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Evaluation failed with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_025 evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Running evaluation with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_025 evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Evaluation failed with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_025 evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Running evaluation with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_06 evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Evaluation failed with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_06 evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Running evaluation with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_06 evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Evaluation failed with config: seeds=seed_206 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_06 evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Running evaluation with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=greedy evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Evaluation failed with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=greedy evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Running evaluation with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=greedy evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Evaluation failed with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=greedy evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Running evaluation with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_025 evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Evaluation failed with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_025 evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Running evaluation with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_025 evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Evaluation failed with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_025 evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Running evaluation with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_06 evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Evaluation failed with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_06 evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
Running evaluation with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_06 evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Evaluation failed with config: seeds=seed_42 model=llama2 tokenizer=llama2 dataset=all_domains_1_samples generation=temp_06 evaluation_dataset=test_set_2 eval=number_list_fact_first_few_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=untrained
Job 11 completed at Do 20. Feb 11:04:04 CET 2025

============================= JOB FEEDBACK =============================

NodeName=uc2n507
Job ID: 25296016
Cluster: uc2
User/Group: fr_rf1031/fr_fr
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 10
CPU Utilized: 01:00:48
CPU Efficiency: 9.79% of 10:20:50 core-walltime
Job Wall-clock time: 01:02:05
Memory Utilized: 26.70 GB
Memory Efficiency: 74.17% of 36.00 GB
