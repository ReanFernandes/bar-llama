# this must be set in the slurm bash, depending on which combination must be checked
training_status: untrained # "trained" or  "untrained"
quantisation_status: full_model # "quantised_model" or "full_model"

#hardcoded for this config file. Not to be changed
train_config_label: json_fact_first_zero_shot_unstructured
model_label: ${model.model_label}
eval_model_name: ${eval.model_label}_${eval.train_config_label}
mode: "eval"
pipeline_available: None # again must be true or false, trained models cant run pipeline, only untrained models can
lora_adapter_path: ${hydra:runtime.cwd}/sft_adapters/${eval.eval_model_name}
output_directory: ${hydra:runtime.cwd}/model_outputs/raw_responses/${eval.training_status}_${eval.quantisation_status}/${eval.eval_model_name} # this will need to be appended with the test set label to complete the path

prompt: 
  system_prompt: ${hydra:runtime.cwd}/prompt/system_prompt/system # this thing is completed in the prompt handler to put together the actual system prompt file name
  prompt_type: zero_shot  # "few_shot" or "zero_shot"
  example_path: ${hydra:runtime.cwd}/prompt/examples/unstructured_example.json
  explanation_type: unstructured # "structured" or "unstructured"
  response_type: fact_first # "answer_first" or "fact_first"
  response_format: json # "json" or "markdown" or "number_list"
  store_prompt: False # by default, since we dont care about storing the question and stuff, this is only set to true when we make the training dataset