Running configuration: seeds=seed_21 dataset=all_domains_1_samples generation=greedy evaluation_dataset=test_set_1 eval=json_fact_first_zero_shot_unstructured ++eval.quantisation_status=full_model ++eval.training_status=trained
[2025-01-12 16:07:36,331][root][INFO] - Setting global seed to 21
[2025-01-12 16:07:36,337][root][INFO] - Running evaluation of the trained model on the test_set_1
[2025-01-12 16:07:36,337][root][INFO] - Current evaluation config is : 
 Prompt type : zero_shot 
 Response type : fact_first 
 Explanation type : unstructured 
 Response Format : json 
[2025-01-12 16:07:36,338][root][INFO] - Loading dataset from /work/dlclarge1/fernandr-thesis_workspace/bar-llama/dataset/test_sets/bar_set_1.json
[2025-01-12 16:07:36,339][root][INFO] - Dataset loaded successfully, indexing questions...
[2025-01-12 16:07:36,340][root][INFO] - Indexing complete, sampling of questions set to False
[2025-01-12 16:07:36,340][root][INFO] - Questions selected, dataset contains 99 questions with 14.142857142857142 questions per domain
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: write).
Your token has been saved to /home/fernandr/.cache/huggingface/token
Login successful
[2025-01-12 16:07:36,494][root][INFO] - Loading model : meta-llama/Llama-2-7b-hf
[2025-01-12 16:07:36,749][root][INFO] - Full model selected, loading model
[2025-01-12 16:07:39,105][root][INFO] - Tokenizer special tokens: {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'} have been added
[2025-01-12 16:07:41,370][root][INFO] - Fine-tuned model selected, loading adapter
[2025-01-12 16:07:41,371][root][WARNING] - Inference will be done using model.generate instead of hf pipeline since peft model is not compatible with it
