Running configuration: seeds=seed_21 dataset=all_domains_all_samples  train=json_fact_first_few_shot_unstructured
[2025-01-12 12:47:07,849][root][INFO] - Global seed set to 21
[2025-01-12 12:47:07,849][root][WARNING] - No quantisation will be done on loaded model, THIS IS A LORA FINE-TUNING RUN
[2025-01-12 12:47:07,849][root][WARNING] - Following flags are set for the run : 
 Use Quantisation before fine-tuning : False 
 Perform Validation on epoch end : False
[2025-01-12 12:47:07,849][root][INFO] - Running Fine-tuning on the all_domains_all_samples dataset
[2025-01-12 12:47:07,850][root][INFO] - Current training config is : 
 Prompt type : few_shot 
 Response type : fact_first 
 Explanation type : unstructured 
 Response Format : json 
[2025-01-12 12:47:16,358][root][INFO] - Loading dataset from /work/dlclarge1/fernandr-thesis_workspace/bar-llama/dataset/seed_dataset/raw_dataset.json
[2025-01-12 12:47:16,536][root][INFO] - Dataset loaded successfully, indexing questions...
[2025-01-12 12:47:16,539][root][INFO] - Indexing complete, sampling of questions set to True
[2025-01-12 12:47:16,539][root][INFO] - Questions selected, dataset contains 1542 questions with 220.28571428571428 questions per domain
[2025-01-12 12:47:16,576][root][INFO] - Prompt Handler initialized with configuration: {'prompt_type': 'few_shot', 'example_path': '${hydra:runtime.cwd}/prompt/examples/unstructured_example.json', 'explanation_type': 'unstructured', 'response_type': 'fact_first', 'response_format': 'json', 'store_prompt': True, 'system_prompt': '${hydra:runtime.cwd}/prompt/system_prompt/system_${train.prompt.response_format}_${train.prompt.response_type}_${train.prompt.explanation_type}.txt', 'include_system_prompt': True}
