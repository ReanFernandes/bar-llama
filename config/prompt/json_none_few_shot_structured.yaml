# This is a few shot prompt

system_prompt: ${hydra:runtime.cwd}/system_prompts/system # the way i made the system prompts, this will have to be suffixed with the config in the prompt handler.
prompt_type: "few_shot" # either few_shot or zero_shot
example_path: ${hydra:runtime.cwd}/dataset/data_generation_pipline/restructure_data/restructured_example.json
fact_first : True # if the the model is required to provide explanation before the chosen answer, then set true.
response_format: "json"
response_type: "none"
mode: "eval"
model_name: "llama2"
structured_explanation: true
store_prompt: false # flag to use such that the generated prompt will be add to a prompt list within the class, which can be dumped to a json file at the end. 
pipeline_available: None 
explanation_type: "structured"